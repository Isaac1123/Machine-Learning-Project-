{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b5a62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas            as pd                          # data science essentials\n",
    "import matplotlib.pyplot as plt                         # data visualization\n",
    "import seaborn           as sns                         # enhanced data viz\n",
    "from sklearn.model_selection import train_test_split    # train-test split\n",
    "from sklearn.linear_model import LogisticRegression     # logistic regression\n",
    "import statsmodels.formula.api as smf                   # logistic regression\n",
    "from sklearn.metrics import confusion_matrix            # confusion matrix\n",
    "from sklearn.metrics import roc_auc_score               # auc score\n",
    "from sklearn.neighbors import KNeighborsClassifier      # KNN for classification\n",
    "from sklearn.neighbors import KNeighborsRegressor       # KNN for regression\n",
    "from sklearn.preprocessing import StandardScaler        # standard scaler\n",
    "from sklearn.tree import DecisionTreeClassifier         # classification trees\n",
    "from sklearn.tree import plot_tree                      # tree plots\n",
    "from sklearn.model_selection import RandomizedSearchCV  # hyperparameter tuning\n",
    "from sklearn.metrics import make_scorer                 # customizable scorer\n",
    "from sklearn.ensemble import RandomForestClassifier     # random forest\n",
    "from sklearn.ensemble import GradientBoostingClassifier # gbm\n",
    "\n",
    "\n",
    "########################################\n",
    "# loading data and setting display options\n",
    "########################################\n",
    "# loading data\n",
    "GOT = pd.read_excel('./GOT_character_predictions.xlsx')\n",
    "\n",
    "# setting pandas print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# displaying the head of the dataset\n",
    "GOT.head(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd52209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking missing value\n",
    "GOT.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70702d20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking the population of specific family/title/culture \n",
    "#GOT['house'].value_counts(normalize=False, sort=True, ascending=False)\n",
    "#GOT['title'].value_counts(normalize=False, sort=True, ascending=False)\n",
    "#GOT['culture'].value_counts(normalize=False, sort=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecf711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the correlation bwtween each variables\n",
    "GOT_corr = GOT.corr(method = 'pearson')\n",
    "GOT_corr.loc[ : , 'isAlive'].round(decimals = 2).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdac53cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up dummy variables for the 'house'\n",
    "GOT = pd.get_dummies(data = GOT,\n",
    "                     columns = ['house'],\n",
    "                     prefix = \"dm\",\n",
    "                     drop_first = True)\n",
    "\n",
    "GOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ad7d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring explanatory variables\n",
    "GOT_data= GOT.drop('isAlive', axis=1)\n",
    "\n",
    "# declaring response variable\n",
    "GOT_target= GOT.loc[:,'isAlive']\n",
    "\n",
    "# train-test split with stratification\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "                                   GOT_data,\n",
    "                                   GOT_target,\n",
    "                                   test_size    = 0.1,\n",
    "                                   random_state = 219,\n",
    "                                   stratify     = GOT_target) # preserving balance\n",
    "\n",
    "# merging training data for statsmodels\n",
    "GOT_train = pd.concat([x_train, y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2567771e",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# instantiating a logistic regression model object\n",
    "logit_full = smf.logit(formula   = \"\"\"isAlive ~ book4_A_Feast_For_Crows + \n",
    "                                                numDeadRelations + \n",
    "                                                popularity +\n",
    "                                                book1_A_Game_Of_Thrones\"\"\", \n",
    "                                                data = GOT_train)\n",
    "\n",
    "\n",
    "# FITTING the model object\n",
    "results_full = logit_full.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_full.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e034d346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explanatory sets from last session\n",
    "\n",
    "# creating a dictionary to store candidate models\n",
    "\n",
    "candidate_dict = {\n",
    "\n",
    " # full model\n",
    " \"logit_full\"   : [\"book4_A_Feast_For_Crows\", \"numDeadRelations\", \"popularity\", \"book1_A_Game_Of_Thrones\",\n",
    "                   \"S.No\", \"dm_Night's Watch\", \"dm_House Targaryen\"],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbcaf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Logistic Regression####\n",
    "\n",
    "# train/test split with the full model\n",
    "GOT_data   =  GOT.loc[ : , candidate_dict['logit_full']]\n",
    "GOT_target =  GOT.loc[ : , 'isAlive']\n",
    "\n",
    "# train-test split with stratification\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "                                   GOT_data,\n",
    "                                   GOT_target,\n",
    "                                   test_size    = 0.1,\n",
    "                                   random_state = 219,\n",
    "                                   stratify     = GOT_target) # preserving balance\n",
    "\n",
    "\n",
    "# INSTANTIATING a logistic regression model\n",
    "logreg = LogisticRegression(solver = 'lbfgs',\n",
    "                            C = 1,\n",
    "                            warm_start = False,\n",
    "                            random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "logreg_fit = logreg.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "logreg_pred = logreg_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', logreg_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', logreg_fit.score(x_test, y_test).round(4))\n",
    "print('Logistic AUC Score:', roc_auc_score(y_true  = y_test,\n",
    "                                            y_score = logreg_pred).round(4))\n",
    "\n",
    "# saving scoring data for future use\n",
    "logreg_train_score = logreg_fit.score(x_train, y_train).round(4) # accuracy\n",
    "logreg_test_score  = logreg_fit.score(x_test, y_test).round(4) # accuracy\n",
    "logreg_auc_score = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = logreg_pred).round(decimals = 4)\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "logreg_tn, \\\n",
    "logreg_fp, \\\n",
    "logreg_fn, \\\n",
    "logreg_tp = confusion_matrix(y_true = y_test, y_pred = logreg_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {logreg_tn}\n",
    "False Positives: {logreg_fp}\n",
    "False Negatives: {logreg_fn}\n",
    "True Positives : {logreg_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58278ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "####KNN Classification Model####\n",
    "\n",
    "# train-test split with the scaled data\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            GOT_data,\n",
    "            GOT_target,\n",
    "            random_state = 219,\n",
    "            test_size    = 0.1,\n",
    "            stratify     = GOT_target)\n",
    "\n",
    "#INSTANTIATING a KNN classification model with optimal neighbors\n",
    "knn_opt = KNeighborsClassifier()\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "knn_fit = knn_opt.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "knn_pred = knn_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', knn_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', knn_fit.score(x_test, y_test).round(4))\n",
    "print('KNN AUC Score    :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data\n",
    "knn_train_score = knn_fit.score(x_train, y_train).round(4)\n",
    "knn_test_score  = knn_fit.score(x_test, y_test).round(4)\n",
    "\n",
    "\n",
    "# saving AUC score\n",
    "knn_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                y_score = knn_pred).round(4)\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "knn_tn, \\\n",
    "knn_fp, \\\n",
    "knn_fn, \\\n",
    "knn_tp = confusion_matrix(y_true = y_test, y_pred = knn_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {knn_tn}\n",
    "False Positives: {knn_fp}\n",
    "False Negatives: {knn_fn}\n",
    "True Positives : {knn_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38cf31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Classification Trees####\n",
    "\n",
    "# INSTANTIATING a classification tree object\n",
    "tree_pruned = DecisionTreeClassifier(max_depth=8,\n",
    "                                     min_samples_leaf=25,\n",
    "                                     random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "tree_pruned_fit = tree_pruned.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "tree_pruned_pred = tree_pruned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Training ACCURACY:', tree_pruned_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', tree_pruned_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = tree_pruned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "pruned_tree_train_score = tree_pruned_fit.score(x_train, y_train).round(4) # accuracy\n",
    "pruned_tree_test_score  = tree_pruned_fit.score(x_test, y_test).round(4) # accuracy\n",
    "\n",
    "\n",
    "# saving auc score\n",
    "pruned_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                        y_score = tree_pruned_pred).round(4) # auc\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "pruned_tree_tn, \\\n",
    "pruned_tree_fp, \\\n",
    "pruned_tree_fn, \\\n",
    "pruned_tree_tp = confusion_matrix(y_true = y_test, y_pred = tree_pruned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {pruned_tree_tn}\n",
    "False Positives: {pruned_tree_fp}\n",
    "False Negatives: {pruned_tree_fn}\n",
    "True Positives : {pruned_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4b1ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Random Forest###\n",
    "\n",
    "# INSTANTIATING a random forest model with default values\n",
    "rf_default = RandomForestClassifier(n_estimators     = 500,\n",
    "                                    criterion        = 'entropy',\n",
    "                                    max_depth        = 8,\n",
    "                                    min_samples_leaf = 10,\n",
    "                                    bootstrap        = True,\n",
    "                                    warm_start       = False,\n",
    "                                    random_state     = 219)\n",
    "\n",
    "# FITTING the training data\n",
    "rf_default_fit = rf_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "rf_default_fit_pred = rf_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', rf_default_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', rf_default_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                        y_score = rf_default_fit_pred).round(4))\n",
    "\n",
    "# saving AUC score\n",
    "rf_train_acc = rf_default_fit.score(x_train, y_train).round(4)\n",
    "rf_test_acc  = rf_default_fit.score(x_test, y_test).round(4)\n",
    "rf_auc       = roc_auc_score(y_true  = y_test,\n",
    "                             y_score = rf_default_fit_pred).round(4)\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "rf_tn, \\\n",
    "rf_fp, \\\n",
    "rf_fn, \\\n",
    "rf_tp = confusion_matrix(y_true = y_test, y_pred = rf_default_fit_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {rf_tn}\n",
    "False Positives: {rf_fp}\n",
    "False Negatives: {rf_fn}\n",
    "True Positives : {rf_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d7469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Gradient Boosted Model####\n",
    "\n",
    " \n",
    "# INSTANTIATING with best_estimator\n",
    "gbm_tuned = GradientBoostingClassifier(learning_rate = 0.1,\n",
    "                                       max_depth     = 2,\n",
    "                                       n_estimators  = 350,\n",
    "                                       warm_start    = True,\n",
    "                                       random_state  = 219)\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "gbm_tuned_fit = gbm_tuned.fit(GOT_data, GOT_target)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "gbm_tuned_pred = gbm_tuned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', gbm_tuned_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', gbm_tuned_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = gbm_tuned_pred).round(4))\n",
    "\n",
    "# saving AUC score\n",
    "gbm_train_acc = gbm_tuned_fit.score(x_train, y_train).round(4)\n",
    "gbm_test_acc  = gbm_tuned_fit.score(x_test, y_test).round(4)\n",
    "gbm_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = gbm_tuned_pred).round(4)\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "gbm_tuned_tn, \\\n",
    "gbm_tuned_fp, \\\n",
    "gbm_tuned_fn, \\\n",
    "gbm_tuned_tp = confusion_matrix(y_true = y_test, y_pred = gbm_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {gbm_tuned_tn}\n",
    "False Positives: {gbm_tuned_fp}\n",
    "False Negatives: {gbm_tuned_fn}\n",
    "True Positives : {gbm_tuned_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ffe9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary for model results\n",
    "# appending to model_performance\n",
    "model_performance ={'Model Name'        : ['Logistic', 'KNN', 'Tree', 'Random Forest', 'GBM'],\n",
    "                          \n",
    "                    'Training Accuracy' : [logreg_train_score, knn_train_score, pruned_tree_train_score, rf_train_acc,\n",
    "                                           gbm_train_acc],\n",
    "                          \n",
    "                    'Testing Accuracy'  : [logreg_test_score, knn_test_score, pruned_tree_test_score, rf_test_acc, \n",
    "                                           gbm_test_acc],\n",
    "                          \n",
    "                    'AUC Score'         : [logreg_auc_score, knn_auc_score, pruned_tree_auc_score, rf_auc, gbm_auc],\n",
    "                          \n",
    "                    'Confusion Matrix'  : [(logreg_tn, logreg_fp, logreg_fn, logreg_tp), (knn_tn, knn_fp, knn_fn, knn_tp),\n",
    "                                           (pruned_tree_tn, pruned_tree_fp, pruned_tree_fn, pruned_tree_tp),\n",
    "                                           (rf_tn, rf_fp, rf_fn, rf_tp), \n",
    "                                           (gbm_tuned_tn, gbm_tuned_fp, gbm_tuned_fn, gbm_tuned_tp)],\n",
    "                    'Final Model'       : ['','','','','âœ“']}\n",
    "# converting model_performance into a DataFrame\n",
    "model_performance = pd.DataFrame(model_performance)\n",
    "                                                 \n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556bba73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\\n\\n\\n {'*' * 95}\"\"\")\n",
    "\n",
    "#final model output\n",
    "print(f\"\"\"\n",
    "\\tIn this exercise, I used five models which are Logistic, KNN, Tree, Random Forest, and GBM to seek the fittest model\\n \n",
    "toward the given GOT data, although the train-test gap doesn't have a huge difference that is all around \\033[1m\"{(gbm_test_acc-gbm_train_acc).round(decimals=2)}\"\\033[0m.\\n\n",
    "However, the AUC Score has a significant disparity, since the \\033[1mGradient Boosted Model\\033[0m suit better for the data and has the\\n\n",
    "highest \\033[1mAUC Score of {gbm_auc}\\033[0m I chose this as my final model. Additionally, sensitivity and specificity remain on the great level\\n \n",
    "which is \\033[1m{(gbm_tuned_tp/(gbm_tuned_tp+gbm_tuned_fn)).round(decimals=2)} & {gbm_tuned_tn/(gbm_tuned_tn+gbm_tuned_fp)}\\033[0m respectively, which means that there is only a small likelihood to go to the wrong prediction. Even though\\n\n",
    "it is possible to keep increasing the Accuracy and AUC Score by tuning the hyperparameter option, an extremely positive score\\n\n",
    "appear could be a problem that ought to be aware of such as bias or inappropriate balance. Overall, the performance of\\n\n",
    "\\033[1mConfusion Matrix\\033[0m in GBM model only shows a few errors \\033[1m{(gbm_tuned_tn, gbm_tuned_fp, gbm_tuned_fn, gbm_tuned_tp)}\\033[0m which is quite good in our forecasting. \"\"\")\n",
    "print(f\"\"\"\\n\\n\\n {'*' * 95}\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
