{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "912c036c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mage</th>\n",
       "      <th>meduc</th>\n",
       "      <th>monpre</th>\n",
       "      <th>npvis</th>\n",
       "      <th>fage</th>\n",
       "      <th>feduc</th>\n",
       "      <th>omaps</th>\n",
       "      <th>fmaps</th>\n",
       "      <th>cigs</th>\n",
       "      <th>drink</th>\n",
       "      <th>male</th>\n",
       "      <th>mwhte</th>\n",
       "      <th>mblck</th>\n",
       "      <th>moth</th>\n",
       "      <th>fwhte</th>\n",
       "      <th>fblck</th>\n",
       "      <th>foth</th>\n",
       "      <th>bwght</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>61</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>46</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>48</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>39</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mage  meduc  monpre  npvis  fage  feduc  omaps  fmaps  cigs  drink  male  \\\n",
       "0    69    NaN       5    2.0    62    NaN      4      7    23      9     1   \n",
       "1    68   12.0       3   10.0    61   11.0      4      6    25     11     1   \n",
       "2    71   12.0       3    6.0    46   12.0      2      7    21     12     1   \n",
       "3    59   16.0       1    8.0    48   16.0      7      8    21     10     0   \n",
       "4    48   12.0       4    6.0    39   12.0      2      9    17     13     0   \n",
       "\n",
       "   mwhte  mblck  moth  fwhte  fblck  foth  bwght  \n",
       "0      0      1     0      0      1     0    697  \n",
       "1      1      0     0      1      0     0   1290  \n",
       "2      0      1     0      0      1     0   1490  \n",
       "3      0      0     1      0      0     1   1720  \n",
       "4      1      0     0      1      0     0   1956  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing libraries\n",
    "import pandas as pd # data science essentials\n",
    "import matplotlib.pyplot as plt # essential graphical output\n",
    "import seaborn as sns # enhanced graphical output\n",
    "import numpy as np # mathematical essentials\n",
    "import statsmodels.formula.api as smf # regression modeling\n",
    "from sklearn.model_selection import train_test_split # train/test split\n",
    "from sklearn.linear_model import LinearRegression # linear regression (scikit-learn)\n",
    "import sklearn.linear_model # linear models\n",
    "\n",
    "# specifying file name\n",
    "file = './birthweight_low.xlsx'\n",
    "\n",
    "# reading the file into Python\n",
    "bwdf_low = pd.read_excel(io = file,\n",
    "                         sheet_name = 0,\n",
    "                         header = 0)\n",
    "bwdf_low.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f72b987e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bwght     1.00\n",
       "omaps     0.25\n",
       "fmaps     0.25\n",
       "feduc     0.14\n",
       "mblck     0.13\n",
       "fblck     0.12\n",
       "male      0.11\n",
       "meduc     0.10\n",
       "npvis     0.06\n",
       "moth     -0.02\n",
       "fwhte    -0.04\n",
       "monpre   -0.05\n",
       "foth     -0.08\n",
       "mwhte    -0.11\n",
       "fage     -0.40\n",
       "mage     -0.46\n",
       "cigs     -0.57\n",
       "drink    -0.74\n",
       "Name: bwght, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the correlation bwtween each variables\n",
    "bwdf_corr = bwdf_low.corr(method = 'pearson')\n",
    "bwdf_corr.loc[ : , 'bwght'].round(decimals = 2).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64542e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 No\t\tYes\n",
      "               ---------------------\n",
      "cigarette       | 9\t\t187\n",
      "drink           | 11\t\t185\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 196 entries, 0 to 195\n",
      "Data columns (total 23 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   mage        196 non-null    int64  \n",
      " 1   meduc       196 non-null    float64\n",
      " 2   monpre      196 non-null    int64  \n",
      " 3   npvis       196 non-null    float64\n",
      " 4   fage        196 non-null    int64  \n",
      " 5   feduc       196 non-null    float64\n",
      " 6   omaps       196 non-null    int64  \n",
      " 7   fmaps       196 non-null    int64  \n",
      " 8   cigs        196 non-null    int64  \n",
      " 9   drink       196 non-null    int64  \n",
      " 10  male        196 non-null    int64  \n",
      " 11  mwhte       196 non-null    int64  \n",
      " 12  mblck       196 non-null    int64  \n",
      " 13  moth        196 non-null    int64  \n",
      " 14  fwhte       196 non-null    int64  \n",
      " 15  fblck       196 non-null    int64  \n",
      " 16  foth        196 non-null    int64  \n",
      " 17  bwght       196 non-null    int64  \n",
      " 18  log_bwght   196 non-null    float64\n",
      " 19  log_mage    196 non-null    float64\n",
      " 20  log_fage    196 non-null    float64\n",
      " 21  cigs:drink  196 non-null    int64  \n",
      " 22  fage:mage   196 non-null    int64  \n",
      "dtypes: float64(6), int64(17)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "#manipulate data such as fillna missing value & convert logarithm\n",
    "bwdf_low['log_bwght'] = np.log(bwdf_low['bwght'])\n",
    "bwdf_low['log_mage']  = np.log(bwdf_low['mage'])\n",
    "bwdf_low['log_fage']  = np.log(bwdf_low['fage'])\n",
    "\n",
    "# filling meduc NAs with MEDIAN\n",
    "meduc_median = bwdf_low['meduc'].median()\n",
    "bwdf_low['meduc'].fillna(value = meduc_median,\n",
    "                         inplace = True)\n",
    "# filling feduc NAs with MEDIAN\n",
    "feduc_median = bwdf_low['feduc'].median()\n",
    "bwdf_low['feduc'].fillna(value = feduc_median,\n",
    "                         inplace = True)\n",
    "# filling npvis NAs with MEDIAN\n",
    "npvis_median = bwdf_low['npvis'].median()\n",
    "bwdf_low['npvis'].fillna(value = npvis_median,\n",
    "                         inplace = True)\n",
    "\n",
    "#checking missing value\n",
    "#bwdf_low.isnull().sum(axis=0)\n",
    "\n",
    "# counting the number of zeroes for \n",
    "cigs_zeroes   = len(bwdf_low['cigs'][bwdf_low['cigs']==0])\n",
    "drink_zeroes  = len(bwdf_low['drink'][bwdf_low['drink']==0])\n",
    "print(f\"\"\"\n",
    "                 No\\t\\tYes\n",
    "               ---------------------\n",
    "cigarette       | {cigs_zeroes}\\t\\t{len(bwdf_low) - cigs_zeroes}\n",
    "drink           | {drink_zeroes}\\t\\t{len(bwdf_low) - drink_zeroes}\n",
    "\"\"\")\n",
    "#Because the observations are too few it's usless to get dummies for cig and drink\n",
    "\n",
    "# amplify the significant of two variables (cigarette & drink)\n",
    "bwdf_low['cigs:drink'] = bwdf_low.loc[:,'drink']*bwdf_low.loc[:,'cigs']\n",
    "bwdf_low['fage:mage'] = bwdf_low.loc[:,'fage']*bwdf_low.loc[:,'mage']\n",
    "#check how many usable variables so far\n",
    "bwdf_low.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb931fe",
   "metadata": {},
   "source": [
    "Manipulate data above\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b24d65ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Data\n",
      "-------------\n",
      "X-side: (147, 21)\n",
      "y-side: 147\n",
      "\n",
      "\n",
      "Testing Data\n",
      "------------\n",
      "X-side: (49, 21)\n",
      "y-side: 49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# preparing explanatory variable data\n",
    "birthweight_data   = bwdf_low.drop(['bwght','log_bwght'],\n",
    "                                axis = 1)\n",
    "\n",
    "\n",
    "# preparing response variable data\n",
    "birthweight_target = bwdf_low.loc[ : , 'bwght']\n",
    "\n",
    "\n",
    "# preparing training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            birthweight_data,\n",
    "            birthweight_target,\n",
    "            test_size = 0.25,\n",
    "            random_state = 219)\n",
    "\n",
    "\n",
    "# checking the shapes of the datasets\n",
    "print(f\"\"\"\n",
    "Training Data\n",
    "-------------\n",
    "X-side: {x_train.shape}\n",
    "y-side: {y_train.shape[0]}\n",
    "\n",
    "\n",
    "Testing Data\n",
    "------------\n",
    "X-side: {x_test.shape}\n",
    "y-side: {y_test.shape[0]}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcd4b07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omaps +\n",
      "fmaps +\n",
      "cigs +\n",
      "drink +\n",
      "fage:mage +\n"
     ]
    }
   ],
   "source": [
    "# declaring set of x-variables\n",
    "x_variables = ['omaps','fmaps','cigs','drink','fage:mage']\n",
    "\n",
    "\n",
    "# looping to make x-variables suitable for statsmodels\n",
    "for val in x_variables:\n",
    "    print(f\"{val} +\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fadf1e5",
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  bwght   R-squared:                       0.763\n",
      "Model:                            OLS   Adj. R-squared:                  0.731\n",
      "Method:                 Least Squares   F-statistic:                     24.39\n",
      "Date:                Sun, 05 Dec 2021   Prob (F-statistic):           2.97e-32\n",
      "Time:                        15:21:10   Log-Likelihood:                -1058.9\n",
      "No. Observations:                 147   AIC:                             2154.\n",
      "Df Residuals:                     129   BIC:                             2208.\n",
      "Df Model:                          17                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   1186.1040    470.761      2.520      0.013     254.692    2117.516\n",
      "mage          23.8617     13.850      1.723      0.087      -3.541      51.265\n",
      "meduc         21.3895     18.578      1.151      0.252     -15.367      58.146\n",
      "monpre        16.0086     24.868      0.644      0.521     -33.194      65.211\n",
      "npvis          1.2981      7.266      0.179      0.858     -13.077      15.674\n",
      "fage          37.7124     15.508      2.432      0.016       7.029      68.395\n",
      "feduc         26.7592     16.289      1.643      0.103      -5.469      58.987\n",
      "omaps         -2.8650     24.237     -0.118      0.906     -50.818      45.088\n",
      "cigs         -21.6486     10.434     -2.075      0.040     -42.292      -1.006\n",
      "drink        -59.5693     21.785     -2.734      0.007    -102.671     -16.467\n",
      "fmaps         47.2383     58.412      0.809      0.420     -68.330     162.807\n",
      "male          86.7047     60.531      1.432      0.154     -33.057     206.467\n",
      "mwhte        488.0592    187.256      2.606      0.010     117.569     858.549\n",
      "mblck        399.3116    185.723      2.150      0.033      31.854     766.769\n",
      "moth         298.7333    178.042      1.678      0.096     -53.528     650.994\n",
      "fwhte        374.8716    170.278      2.202      0.029      37.973     711.770\n",
      "fblck        404.5662    194.388      2.081      0.039      19.965     789.167\n",
      "foth         406.6661    185.755      2.189      0.030      39.145     774.187\n",
      "cigs:drink    -3.2958      1.657     -1.989      0.049      -6.574      -0.017\n",
      "fage:mage     -0.8846      0.317     -2.795      0.006      -1.511      -0.258\n",
      "==============================================================================\n",
      "Omnibus:                        2.763   Durbin-Watson:                   1.828\n",
      "Prob(Omnibus):                  0.251   Jarque-Bera (JB):                2.542\n",
      "Skew:                           0.140   Prob(JB):                        0.281\n",
      "Kurtosis:                       3.580   Cond. No.                     2.26e+19\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 9.71e-31. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# merging x_train and y_train so that they can be used in statsmodels\n",
    "birthweight_train = pd.concat([x_train, y_train], axis = 1)\n",
    "\n",
    "# merging x_test and y_test so that they can be used in statsmodels\n",
    "birthweight_test = pd.concat([x_test, y_test], axis = 1)\n",
    "\n",
    "#build a train model\n",
    "lm_best = smf.ols(formula =  \"\"\"bwght ~mage +\n",
    "                                meduc +\n",
    "                                monpre +\n",
    "                                npvis +\n",
    "                                fage +\n",
    "                                feduc +\n",
    "                                omaps +\n",
    "                                cigs +\n",
    "                                drink +\n",
    "                                fmaps +\n",
    "                                male +\n",
    "                                mwhte +\n",
    "                                mblck +\n",
    "                                moth +\n",
    "                                fwhte +\n",
    "                                fblck +\n",
    "                                foth +\n",
    "                                cigs:drink +\n",
    "                                fage:mage\"\"\",\n",
    "                                data = birthweight_train)\n",
    "\n",
    "#fit the train model based on the data\n",
    "results = lm_best.fit()\n",
    "\n",
    "\n",
    "\n",
    "#analyze the summary output\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9058fc26",
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  bwght   R-squared:                       0.723\n",
      "Model:                            OLS   Adj. R-squared:                  0.715\n",
      "Method:                 Least Squares   F-statistic:                     92.51\n",
      "Date:                Sun, 05 Dec 2021   Prob (F-statistic):           1.48e-38\n",
      "Time:                        15:21:10   Log-Likelihood:                -1070.4\n",
      "No. Observations:                 147   AIC:                             2151.\n",
      "Df Residuals:                     142   BIC:                             2166.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   3859.6774    449.436      8.588      0.000    2971.227    4748.128\n",
      "fmaps         93.2086     46.887      1.988      0.049       0.521     185.896\n",
      "cigs         -37.1645      5.057     -7.349      0.000     -47.162     -27.167\n",
      "drink       -105.7488     11.183     -9.456      0.000    -127.856     -83.642\n",
      "fage:mage     -0.2238      0.042     -5.382      0.000      -0.306      -0.142\n",
      "==============================================================================\n",
      "Omnibus:                        4.669   Durbin-Watson:                   1.840\n",
      "Prob(Omnibus):                  0.097   Jarque-Bera (JB):                4.867\n",
      "Skew:                           0.243   Prob(JB):                       0.0877\n",
      "Kurtosis:                       3.748   Cond. No.                     2.81e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.81e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# merging x_train and y_train so that they can be used in statsmodels\n",
    "birthweight_train = pd.concat([x_train, y_train], axis = 1)\n",
    "\n",
    "# merging x_test and y_test so that they can be used in statsmodels\n",
    "birthweight_test = pd.concat([x_test, y_test], axis = 1)\n",
    "\n",
    "#build a train model\n",
    "lm_best = smf.ols(formula =  \"\"\"bwght ~fmaps +\n",
    "                                cigs +\n",
    "                                drink +\n",
    "                                fage:mage\"\"\",\n",
    "                                data = birthweight_train)\n",
    "\n",
    "#fit the train model based on the data\n",
    "results = lm_best.fit()\n",
    "\n",
    "\n",
    "\n",
    "#analyze the summary output\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38747fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying modelin scikit-learn\n",
    "\n",
    "# preparing x-variables from the OLS model\n",
    "ols_data = bwdf_low.loc[:, x_variables]\n",
    "\n",
    "\n",
    "# preparing response variable\n",
    "birthweight_target = bwdf_low.loc[:, 'bwght']\n",
    "\n",
    "\n",
    "###############################################\n",
    "## setting up more than one train-test split ##\n",
    "###############################################\n",
    "# FULL X-dataset (normal Y)\n",
    "x_train_FULL, x_test_FULL, y_train_FULL, y_test_FULL = train_test_split(\n",
    "            birthweight_data,     # x-variables\n",
    "            birthweight_target,   # y-variable\n",
    "            test_size = 0.25,\n",
    "            random_state = 219)\n",
    "\n",
    "\n",
    "# OLS p-value x-dataset (normal Y)\n",
    "x_train_OLS, x_test_OLS, y_train_OLS, y_test_OLS = train_test_split(\n",
    "            ols_data,         # x-variables\n",
    "            birthweight_target,   # y-variable\n",
    "            test_size = 0.25,\n",
    "            random_state = 219)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4c9ced8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Training Score : 0.7231\n",
      "OLS Testing Score  : 0.6783\n",
      "OLS Train-Test Gap : 0.0448\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a model object\n",
    "lr = LinearRegression()\n",
    "\n",
    "\n",
    "# FITTING to the training data\n",
    "lr_fit = lr.fit(x_train_OLS, y_train_OLS)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "lr_pred = lr_fit.predict(x_test_OLS)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('OLS Training Score :', lr.score(x_train_OLS, y_train_OLS).round(4))  # using R-square\n",
    "print('OLS Testing Score  :',  lr.score(x_test_OLS, y_test_OLS).round(4)) # using R-square\n",
    "\n",
    "lr_train_score = lr.score(x_train_OLS, y_train_OLS).round(4)\n",
    "lr_test_score  = lr.score(x_test_OLS, y_test_OLS).round(4)\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('OLS Train-Test Gap :', abs(lr_train_score - lr_test_score).round(4))\n",
    "lr_test_gap = abs(lr_train_score - lr_test_score).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf52d69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('intercept', 3905.14)\n",
      "('omaps', 10.48)\n",
      "('fmaps', 78.02)\n",
      "('cigs', -37.05)\n",
      "('drink', -105.4)\n",
      "('fage:mage', -0.22)\n"
     ]
    }
   ],
   "source": [
    "# zipping each feature name to its coefficient\n",
    "lr_model_values = zip(birthweight_data[x_variables].columns,\n",
    "                      lr_fit.coef_.round(decimals = 2))\n",
    "\n",
    "\n",
    "# setting up a placeholder list to store model features\n",
    "lr_model_lst = [('intercept', lr_fit.intercept_.round(decimals = 2))]\n",
    "\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for val in lr_model_values:\n",
    "    lr_model_lst.append(val)\n",
    "    \n",
    "\n",
    "# checking the results\n",
    "for pair in lr_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03fdb14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Training Score : 0.7223\n",
      "Lasso Testing Score  : 0.6841\n",
      "Lasso Train-Test Gap : 0.0382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yclee\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a model object\n",
    "lasso_model = sklearn.linear_model.Lasso(alpha = 1.0,\n",
    "                                         normalize = True) # default magitude\n",
    "\n",
    "\n",
    "# FITTING to the training data\n",
    "lasso_fit = lasso_model.fit(x_train_OLS, y_train_OLS)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "lasso_pred = lasso_fit.predict(x_test_OLS)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Lasso Training Score :', lasso_model.score(x_train_OLS, y_train_OLS).round(4))\n",
    "print('Lasso Testing Score  :', lasso_model.score(x_test_OLS, y_test_OLS).round(4))\n",
    "\n",
    "\n",
    "## the following code has been provided for you ##\n",
    "\n",
    "# saving scoring data for future use\n",
    "lasso_train_score = lasso_model.score(x_train_OLS, y_train_OLS).round(4) # using R-square\n",
    "lasso_test_score  = lasso_model.score(x_test_OLS, y_test_OLS).round(4)   # using R-square\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('Lasso Train-Test Gap :', abs(lasso_train_score - lasso_test_score).round(4))\n",
    "lasso_test_gap = abs(lasso_train_score - lasso_test_score).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03143e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('intercept', 3973.34)\n",
      "('mage', 7.35)\n",
      "('meduc', 69.4)\n",
      "('monpre', -35.76)\n",
      "('npvis', -103.82)\n",
      "('fage', -0.22)\n"
     ]
    }
   ],
   "source": [
    "# zipping each feature name to its coefficient\n",
    "lasso_model_values = zip(birthweight_data.columns, lasso_fit.coef_.round(decimals = 2))\n",
    "\n",
    "\n",
    "# setting up a placeholder list to store model features\n",
    "lasso_model_lst = [('intercept', lasso_fit.intercept_.round(decimals = 2))]\n",
    "\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for val in lasso_model_values:\n",
    "    lasso_model_lst.append(val)\n",
    "    \n",
    "\n",
    "# checking the results\n",
    "for pair in lasso_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65a5f49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7222\n",
      "Testing Score : 0.6849\n",
      "ARD Train-Test Gap : 0.0373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yclee\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a model object\n",
    "ard_model = sklearn.linear_model.ARDRegression(normalize = False)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "ard_fit = ard_model.fit(x_train_OLS, y_train_OLS)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "ard_pred = ard_fit.predict(x_test_OLS)\n",
    "\n",
    "\n",
    "print('Training Score:', ard_model.score(x_train_OLS, y_train_OLS).round(4))\n",
    "print('Testing Score :', ard_model.score(x_test_OLS, y_test_OLS).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "ard_train_score = ard_model.score(x_train_OLS, y_train_OLS).round(4)\n",
    "ard_test_score  = ard_model.score(x_test_OLS, y_test_OLS).round(4)\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('ARD Train-Test Gap :', abs(ard_train_score - ard_test_score).round(4))\n",
    "ard_test_gap = abs(ard_train_score - ard_test_score).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "901b476a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('intercept', 4038.07)\n",
      "('mage', 0.00177)\n",
      "('meduc', 72.83036)\n",
      "('monpre', -36.67285)\n",
      "('npvis', -106.22424)\n",
      "('fage', -0.22304)\n"
     ]
    }
   ],
   "source": [
    "# zipping each feature name to its coefficient\n",
    "ard_model_values = zip(birthweight_data.columns, ard_fit.coef_.round(decimals = 5))\n",
    "\n",
    "\n",
    "# setting up a placeholder list to store model features\n",
    "ard_model_lst = [('intercept', ard_fit.intercept_.round(decimals = 2))]\n",
    "\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for val in ard_model_values:\n",
    "    ard_model_lst.append(val)\n",
    "    \n",
    "\n",
    "# checking the results\n",
    "for pair in ard_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8441bb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model      Train Score      Test Score\n",
      "-----      -----------      ----------\n",
      "OLS        0.7231           0.6783\n",
      "Lasso      0.7223           0.6841\n",
      "*ARD       0.7222           0.6849\n",
      "\n",
      "* final model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# comparing results\n",
    "\n",
    "print(f\"\"\"\n",
    "Model      Train Score      Test Score\n",
    "-----      -----------      ----------\n",
    "OLS        {lr_train_score}           {lr_test_score}\n",
    "Lasso      {lasso_train_score}           {lasso_test_score}\n",
    "*ARD       {ard_train_score}           {ard_test_score}\n",
    "\n",
    "* final model\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# creating a dictionary for model results\n",
    "model_performance = {\n",
    "    \n",
    "    'Model Type'    : ['OLS', 'Lasso', 'ARD'],\n",
    "           \n",
    "    'Training' : [lr_train_score, lasso_train_score,\n",
    "                                   ard_train_score],\n",
    "           \n",
    "    'Testing'  : [lr_test_score, lasso_test_score,\n",
    "                                   ard_test_score],\n",
    "                    \n",
    "    'Train-Test Gap' : [lr_test_gap, lasso_test_gap,\n",
    "                                        ard_test_gap],\n",
    "                    \n",
    "    'Model Size' : [len(lr_model_lst), len(lasso_model_lst),\n",
    "                                    len(ard_model_lst)],\n",
    "                    \n",
    "    'Model' : [lr_model_lst, lasso_model_lst, ard_model_lst]}\n",
    "\n",
    "\n",
    "# converting model_performance into a DataFrame\n",
    "#model_performance = pd.DataFrame(model_performance)\n",
    "\n",
    "\n",
    "# sending model results to Excel\n",
    "#model_performance.to_excel('./__model_results/linear_model_performance.xlsx',\n",
    "                           #index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01cb521e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " ***********************************************************************************************\n",
      "\n",
      "\tIn this exercise I using three model which is OLS, Lasso, and ARD to run my regression,\n",
      " \n",
      "although they only have minute difference\u001b[1m\"0.0008\"\u001b[0m. The Train-Test Gap has a significant change,\n",
      "\n",
      "in this case smaller is better therefore I decided to take\u001b[1m \"ARD\" \u001b[0mas my final model.\n",
      "\n",
      "The \u001b[1mTraining Score\u001b[0m is 0.7222 and the \u001b[1mTesting Score\u001b[0m is 0.6849 which make my \u001b[1mTrain-Test Gap\u001b[0m around\n",
      "\n",
      "0.037, that give me a great precision of prediction model.\n",
      "\n",
      "\n",
      "\n",
      " ***********************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\\n\\n\\n {'*' * 95}\"\"\")\n",
    "\n",
    "#final model output\n",
    "print(f\"\"\"\n",
    "\\tIn this exercise I using three model which is OLS, Lasso, and ARD to run my regression,\\n \n",
    "although they only have minute difference\\033[1m\"{(lr_train_score-lasso_train_score).round(decimals=4)}\"\\033[0m. The Train-Test Gap has a significant change,\\n\n",
    "in this case smaller is better therefore I decided to take\\033[1m \"ARD\" \\033[0mas my final model.\\n\n",
    "The \\033[1mTraining Score\\033[0m is {ard_train_score} and the \\033[1mTesting Score\\033[0m is {ard_test_score} which make my \\033[1mTrain-Test Gap\\033[0m around\\n\n",
    "{ard_test_gap.round(decimals=3)}, that give me a great precision of prediction model.\"\"\")\n",
    "print(f\"\"\"\\n\\n\\n {'*' * 95}\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
